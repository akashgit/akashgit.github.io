---
layout: default
title: Akash Srivastava
---
<!-- - Our paper [A Bayesian-Symbolic Approach to Learning and Reasoning for Intuitive Physics](/research/a_bayesian_symbolic_approach_t.pdf) got accepted at Neurips 2021. -->
<!-- - Our paper [Targeted Neural Dynamical Modeling](/research/targeted_neural_dynamical_mode.pdf) got accepted at Neurips 2021.
- New paper [Scaling Densities for Improved Density Ratio Estimation](/research/CoB.pdf).
- New paper [Equivariant Self-Supervised Learning: Encouraging Equivariance in Representations](https://arxiv.org/pdf/2111.00899.pdf).
- New paper [Improving the Reconstruction of Disentangled Representation Learners via Multi-Stage Modelling](https://arxiv.org/abs/2010.13187).
- New paper [not-so-BigGAN: Generating High-Fidelity Images on Small Compute with Wavelet-based Super-Resolution](https://arxiv.org/abs/2009.04433).
- Our paper [Generative Ratio Matching Networks](https://openreview.net/pdf?id=SJg7spEYDS) got accepted at ICLR 2020.
- Our paper [Scalable Spike Source Localization in Extracellular Recordings using Amortized Variational Inference](http://akashgit.github.io/research/cole.pdf) got accepted at Neurips 2019.
- New paper [SimVAE: Simulator-Assisted Training for Interpretable Generative Models.](http://akashgit.github.io/research/simvae.pdf)
- New paper [BreGMN: scaled-Bregman Generative Modeling Networks.](http://akashgit.github.io/research/BregmanGAN2020.pdf)
- Our paper, [Variational Russian Roulette for Deep Bayesian Nonparametrics.](http://xuk.ai/assets/xu2019rave.pdf) got accepted at ICML, 2019.
- Our paper, [Synthesis of Differentiable Functional Programs for Lifelong Learning](https://arxiv.org/abs/1804.00218) got accepted at NeuriPS, 2018. 
- Our paper, [Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam](https://arxiv.org/abs/1806.04854) got accepted at ICML, 2018.
- I will be at the RIKEN Center for Advanced Intelligence Project, Japan during most of Feburary (2018) as a visiting researcher.
- I will be interning at Microsoft Research with Dr John Winn, Cambridge this (2017) summer. -->
<!-- <div class="blurb">
	<h1>Akash Srivastava</h1>
	<p>![profile](/profile.jpg) I'm a PhD student in the <a href="http://www.ed.ac.uk/informatics/about/location/forum">Informatics Forum </a>, 
		University of Edinburgh.</p>
	<p>I'm currently working with <a href="http://homepages.inf.ed.ac.uk/csutton/">Dr Charles Sutton</a> 
		on <a href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf"> ![profile](/profile.jpg)  <img style="float: left;" src="/profile.jpg">
		variational inference</a> and <br>interactive machine learning primarily for unsupervised models. </p>
</div><!-- /.blurb --> 

<img style="float: right;" src="profile_akash.jpeg">

#   Akash Srivastava
I am a PI at the [MIT-IBM AI Research Lab](https://mitibmwatsonailab.mit.edu/) and the Chief Scientist at EBI within the Exploratory Sciences unit of IBM Research. I also serve as the technical lead for the synthetic data generation efforts at IBM. My lab is located on campus, at 314 Main St (new MIT Meuseum building) in Cambridge, where my group works on topics ranging from self-supervised learning, deep generative models, differential and statistical privacy, density ratio estimation, machine common-sense, model calibration and uncertainity quantification and foundational models. Before joining MIT-IBM, I obtained my PhD at the University of Edinburgh where I worked with [Prof Charles Sutton](https://homepages.inf.ed.ac.uk/csutton/) and [Prof Michael U. Gutmann](https://michaelgutmann.github.io/) on [variational inference for generative models and deep learning](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2h6SZeEAAAAJ&cstart=20&pagesize=80&citation_for_view=2h6SZeEAAAAJ:Tiz5es2fbqcC).

---
# Current Projects/Grants
- PI, MIT-IBM, 2023: Generative Modeling for Complex Mechanical Systems with Constraints. In collaboration with [Prof. Faez Ahmed (MIT)](https://decode.mit.edu/)
- PI, MIT-IBM, 2023: Synthetic data and randomness in business and societal decision-making. In collaboration with [Prof. Dean Eckles (MIT)](https://www.deaneckles.com/)
- PI, MIT-IBM, 2023: Generative active learning of atomistic simulators for silica materials. In collaboration with [Prof. Rafael Gomez-Bombarelli (MIT)](http://gomezbombarelli.mit.edu/)
- PI, MIT-IBM, 2023: Rethinking the vehicle routing problem under the lens of modern machine learning techniques. In collaboration with [Dr. Matthias Winkenbach (MIT)](https://ctl.mit.edu/about/bio/matthias-winkenbach)
- co-PI, MIT-IBM, 2023: Teaching Foundation Models 3D. Led by [Prof. Vincent Sitzmann (MIT)](https://www.vincentsitzmann.com/) and [Dr. Leonid Karlinsky (MIT-IBM Research)](https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en)
- PI, [Climate Change AI](https://www.climatechange.ai/), 2022: Towards greener last-mile operations: Supporting cargo-bike logistics through optimized routing of multi-modal urban delivery fleets.
- PI, MIT-IBM, 2021: Hybrid Generative Models. In collaboration with [Prof. Faez Ahmed (MIT)](https://decode.mit.edu/)
- Co-PI, MIT-IBM, 2021: Representation Learning as a Tool for Causal Discovery. Led by [Prof. Caroline Uhler (MIT)](https://www.carolineuhler.com/) and [Dr. Kristjan H Greenewald (MIT-IBM Research)](https://kgreenewald.github.io/)
- PI, MIT-IBM, 2020: Learning Priors for Transfer. In collaboration with [Prof. Pulkit Agarwal (MIT)](https://people.csail.mit.edu/pulkitag/)
- Co-PI, DARPA, 2019: Machine Common Sense. Led by [Prof. Josh Tenenbaum (MIT)](http://web.mit.edu/cocosci/josh.html) and [Dr. Dan Gutfreund (MIT-IBM Research)](https://mitibmwatsonailab.mit.edu/people/dan-gutfreund/)

# News:
- __I am always looking for talented students to join my group interns and collaborators. If you are a student at MIT, looking for an internship/work-experience/collaboration and are interested in any of the following topics, please get in touch: 1. Information obfuscation and synthetic data generation. 2. Time-series differential privacy. 3. User-level differential privacy. 4. Deep generative modeling for domains that require high precision and constraint satisfaction 5. Density ratio estimation in high-dimensional data 6. Understanding large language models using probabilistic graphical modeling 7. Uncertainty quantification and model calibration in self-supervised representation learning.__
- Read about how MIT-IBM lab and IBM Research are using synthetic data generation method to tackle real world problems in this [blog post](https://research.ibm.com/blog/synthetic-data-explained). It also features work from our work on generative models for engineering design problems.
- Our project on generative models for inverse linkage synthesis was recently featured in [MIT's spectrum magazine](https://spectrum.mit.edu/fall-2022/design-for-anything-and-everything/).

---



