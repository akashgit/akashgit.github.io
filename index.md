---
layout: default
title: Akash Srivastava
---

<!-- <div class="blurb">
	<h1>Akash Srivastava</h1>
	<p>![profile](/profile.jpg) I'm a PhD student in the <a href="http://www.ed.ac.uk/informatics/about/location/forum">Informatics Forum </a>, 
		University of Edinburgh.</p>
	<p>I'm currently working with <a href="http://homepages.inf.ed.ac.uk/csutton/">Dr Charles Sutton</a> 
		on <a href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf"> ![profile](/profile.jpg)  <img style="float: left;" src="/profile.jpg">
		variational inference</a> and <br>interactive machine learning primarily for unsupervised models. </p>
</div><!-- /.blurb --> 

<img style="float: right;" src="profile_akash.jpeg">

#   Akash Srivastava
<!-- I am a research scientist at the new [MIT-IBM lab](https://mitibmwatsonailab.mit.edu/) in Cambridge, MA where I work on unsupervised representation learning, deep generative models, contrastive learning and more recently, on [building machines with child-like common-sense and intuitive physics](https://bcs.mit.edu/) using probabilistic modeling and Bayesian inference. 
Before this, I was a PhD student in the [Informatics Forum](http://www.ed.ac.uk/informatics/about/location/forum) at the University of Edinburgh where I worked with [Dr Charles Sutton](http://homepages.inf.ed.ac.uk/csutton/) and [Dr Michael U. Gutmann](https://sites.google.com/site/michaelgutmann/) on variational inference for generative models using deep learning. -->
I am a principal investigator and research scientist at the [MIT-IBM AI Research Lab](https://mitibmwatsonailab.mit.edu/) in Cambridge, MA, where I work on self-supervised learning with [Prof Pulkit Agarwal's group](https://people.csail.mit.edu/pulkitag/), hybrid generative models with [Prof Faez Ahmed's group](https://decode.mit.edu/), density ratio estimation with [Prof Michael U. Gutmann](https://michaelgutmann.github.io/) and more recently, on machine common-sense and intuitive physics with [Prof Josh Tenenbaum's group](http://web.mit.edu/cocosci/josh.html) and causal discovery with [Prof Caroline Uhler](https://www.carolineuhler.com/). Before joining MIT-IBM, I obtained my PhD at the University of Edinburgh where I worked with [Prof Charles Sutton](https://homepages.inf.ed.ac.uk/csutton/) and [Prof Michael U. Gutmann](https://michaelgutmann.github.io/) on [variational inference for generative models and deep learning](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=2h6SZeEAAAAJ&cstart=20&pagesize=80&citation_for_view=2h6SZeEAAAAJ:Tiz5es2fbqcC).

---
# Current Projects/Grants
- PI, Climate Change AI, 2022: Towards greener last-mile operations: Supporting cargo-bike logistics through optimized routing of multi-modal urban delivery fleets.
- PI, MIT-IBM, 2021: Hybrid Generative Models. In collaboration with Prof. Faez Ahmed (MIT)
- Co-PI, MIT-IBM, 2021: Representation Learning as a Tool for Causal Discovery. Led by Prof. Caroline Uhler (MIT) and Kristjan H Greenewald (MIT-IBM Research)
- PI, MIT-IBM, 2020: Learning Priors for Transfer. In collaboration with Prof. Pulkit Agarwal (MIT)
- Co-PI, DARPA, 2019: Machine Common Sense. Led by Prof. Josh Tenenbaum (MIT) and Dan Gutfreund (MIT-IBM Research)

# News:
- Our paper [A Bayesian-Symbolic Approach to Learning and Reasoning for Intuitive Physics](/research/a_bayesian_symbolic_approach_t.pdf) got accepted at Neurips 2021.
- Our paper [Targeted Neural Dynamical Modeling](/research/targeted_neural_dynamical_mode.pdf) got accepted at Neurips 2021.
- New paper [Scaling Densities for Improved Density Ratio Estimation](/research/CoB.pdf).
- New paper [Equivariant Self-Supervised Learning: Encouraging Equivariance in Representations](https://arxiv.org/pdf/2111.00899.pdf).
- New paper [Improving the Reconstruction of Disentangled Representation Learners via Multi-Stage Modelling](https://arxiv.org/abs/2010.13187).
- New paper [not-so-BigGAN: Generating High-Fidelity Images on Small Compute with Wavelet-based Super-Resolution](https://arxiv.org/abs/2009.04433).
- Our paper [Generative Ratio Matching Networks](https://openreview.net/pdf?id=SJg7spEYDS) got accepted at ICLR 2020.
- Our paper [Scalable Spike Source Localization in Extracellular Recordings using Amortized Variational Inference](http://akashgit.github.io/research/cole.pdf) got accepted at Neurips 2019.
- New paper [SimVAE: Simulator-Assisted Training for Interpretable Generative Models.](http://akashgit.github.io/research/simvae.pdf)
- New paper [BreGMN: scaled-Bregman Generative Modeling Networks.](http://akashgit.github.io/research/BregmanGAN2020.pdf)
- Our paper, [Variational Russian Roulette for Deep Bayesian Nonparametrics.](http://xuk.ai/assets/xu2019rave.pdf) got accepted at ICML, 2019.
- Our paper, [Synthesis of Differentiable Functional Programs for Lifelong Learning](https://arxiv.org/abs/1804.00218) got accepted at NeuriPS, 2018. 
- Our paper, [Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam](https://arxiv.org/abs/1806.04854) got accepted at ICML, 2018.
- I will be at the RIKEN Center for Advanced Intelligence Project, Japan during most of Feburary (2018) as a visiting researcher.
- I will be interning at Microsoft Research with Dr John Winn, Cambridge this (2017) summer.

---



